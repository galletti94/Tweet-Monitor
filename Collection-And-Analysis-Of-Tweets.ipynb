{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collecting and Analyzing Tweets\n",
    "\n",
    "To replicate my set up and run this notebook, please visit https://github.com/galletti94/Tweet-Monitor \n",
    "\n",
    "\n",
    "### Let's get some tweets!\n",
    "\n",
    "For this we use the twitter api which requires you to have a twitter account. Twitter gives you access keys which are unique to your account. These keys will go in a file called keys.txt which we make sure to include in the .gitignore file so that these are not made publically available. Let's get started!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracking: United States\n"
     ]
    }
   ],
   "source": [
    "import tweepy\n",
    "import json\n",
    "from pymongo import MongoClient\n",
    "from __future__ import print_function\n",
    "\n",
    "MONGO_HOST = 'mongodb://localhost/usa_db'\n",
    "\n",
    "LOCATION = [-127.3,24.1,-65.9,51.8]\n",
    "\n",
    "# get credentials from the keys.txt file\n",
    "keys_file = open(\"keys.txt\")\n",
    "lines = keys_file.readlines()\n",
    "consumer_key = lines[0].rstrip()\n",
    "consumer_secret = lines[1].rstrip()\n",
    "access_token = lines[2].rstrip()\n",
    "access_token_secret = lines[3].rstrip()\n",
    "keys_file.close()\n",
    "\n",
    "class StreamListener(tweepy.StreamListener):\n",
    "    # This is a class provided by tweepy to access the Twitter Streaming API.\n",
    "\n",
    "    def on_connect(self):\n",
    "        # Called initially to connect to the Streaming API\n",
    "        print(\"You are now connected to the streaming API.\")\n",
    "\n",
    "    def on_error(self, status_code):\n",
    "        print('An Error has occured: ' + repr(status_code))\n",
    "        return False\n",
    "\n",
    "    def on_data(self, data):\n",
    "        try:\n",
    "            client = MongoClient(MONGO_HOST)\n",
    "            db = client.usa_db\n",
    "            \n",
    "            datajson = json.loads(data) # Decode the JSON from Twitter\n",
    "\n",
    "            # grab the 'created_at' data from the Tweet to use for display\n",
    "            created_at = datajson['created_at']\n",
    "            \n",
    "            # only get tweets that have geo location enabled\n",
    "            if datajson['coordinates']:\n",
    "                # print out a message to the screen that we have collected a tweet\n",
    "                print(\"Tweet collected at \" + str(created_at))\n",
    "                db.usa_tweets_collection.insert_one(datajson) #insert into db\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "listener = StreamListener(api=tweepy.API(wait_on_rate_limit=True))\n",
    "streamer = tweepy.Stream(auth=auth, listener=listener)\n",
    "\n",
    "print(\"Tracking: \" + 'United States')\n",
    "streamer.filter(locations=LOCATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome - now we can let this run and collect some tweets!\n",
    "\n",
    "After waiting a few minutes for your database to fill up, you can hit CTRL + C to stop the collection and stop the program.\n",
    "\n",
    "### What do we have here?\n",
    "\n",
    "Let's take a look at the tweets we collected!\n",
    "\n",
    "#### Where are in the US are these tweets coming from?\n",
    "\n",
    "We can use folium to map the coordinates of the tweets on a map:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "import folium\n",
    "\n",
    "client = MongoClient('localhost', 27017)\n",
    "db = client['usa_db']\n",
    "collection = db['usa_tweets_collection']\n",
    "tweets_iterator = collection.find()\n",
    "\n",
    "mymap = folium.Map(location=[45.372, -121.6972], zoom_start=4)\n",
    "\n",
    "for tweet in tweets_iterator:\n",
    "    folium.CircleMarker(location=list(reversed(tweet['coordinates']['coordinates']))).add_to(mymap)\n",
    "    \n",
    "mymap.save('map.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the above and opening map.html in a browser gives the following:\n",
    "\n",
    "![Image](./tweetsUSA.jpg)\n",
    "\n",
    "Nice. Let's look at what kinds of emojis people use!\n",
    "\n",
    "#### Emojis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('‚ù§', 164), ('üî•', 160), ('üéÑ', 121), ('üòç', 118), ('üèæ', 112), ('üèº', 112), ('üòÇ', 104), ('üèª', 90), ('üèΩ', 81), ('‚ú®', 79), ('üôå', 68), ('üí™', 67), ('üíØ', 62), ('üôè', 60), ('‚ùÑ', 60)]\n"
     ]
    }
   ],
   "source": [
    "from emoji import UNICODE_EMOJI\n",
    "\n",
    "client = MongoClient('localhost', 27017)\n",
    "db = client['usa_db']\n",
    "collection = db['usa_tweets_collection']\n",
    "tweets_iterator = collection.find()\n",
    "\n",
    "d = dict()\n",
    "i = 0\n",
    "for tweet in tweets_iterator:\n",
    "  for ch in list(tweet['text']):  #remember emojis are characters not words\n",
    "    if ch in UNICODE_EMOJI:\n",
    "      try:\n",
    "        d[ch] += 1\n",
    "      except KeyError:\n",
    "        d[ch] = 1\n",
    "\n",
    "d = sorted(d.items(), key=lambda x: -x[1])\n",
    "print(d[:15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When this was written it was close to christmas so I guess the second and third emojis make sense.\n",
    "\n",
    "\n",
    "#### Sentiment Analysis\n",
    "\n",
    "\n",
    "We can analyze the words of the tweets to get a sense of whether the tweet has positive sentiment or negative sentiment. We can aggregate these and get a sense of the general mood of the US at this time of year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('pos', 74), ('neg', 26)]\n",
      "\n",
      "Number of Tweets =  100\n",
      "\n",
      "Number of tweets with location enabled =  95\n"
     ]
    }
   ],
   "source": [
    "from pymongo import MongoClient\n",
    "from textblob import TextBlob\n",
    "from textblob.sentiments import NaiveBayesAnalyzer\n",
    "\n",
    "client = MongoClient('localhost', 27017)\n",
    "db = client['usa_db']\n",
    "collection = db['usa_tweets_collection']\n",
    "tweets_iterator = collection.find()\n",
    "\n",
    "tweetCnt = 0\n",
    "locEnabled = 0\n",
    "d = dict()\n",
    "only100 = 100\n",
    "for tweet in tweets_iterator:\n",
    "    if only100 <= 0:\n",
    "        break\n",
    "    only100 -= 1\n",
    "    tweetCnt += 1\n",
    "    if tweet['user']['location']:\n",
    "      locEnabled += 1\n",
    "    \n",
    "    blob = TextBlob(tweet['text'], analyzer=NaiveBayesAnalyzer())\n",
    "    try:\n",
    "        d[blob.sentiment.classification] += 1\n",
    "    except KeyError:\n",
    "        d[blob.sentiment.classification] = 1\n",
    "\n",
    "d = sorted(d.items(), key=lambda x: -x[1])\n",
    "print(d)\n",
    "print()\n",
    "print('Number of Tweets = ', tweetCnt)\n",
    "print()\n",
    "print('Number of tweets with location enabled = ', locEnabled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like a majority of tweets have positive sentiment but this analysis was only conducted on a subset of the data collected since sentiment analysis is expensive to compute.\n",
    "\n",
    "Maybe next we can see which emojis are correlated with which sentiment!\n",
    "\n",
    "#### Emoji vs Sentiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive emojis =  [('üåπ', 9), ('‚ù§', 9), ('‚ú®', 8), ('üéÑ', 6), ('üé∂', 6)]\n",
      "\n",
      "negative_emojis =  [('üò≠', 7), ('üî•', 6), ('üí¶', 4), ('‚ù£', 2), ('‚õì', 2)]\n"
     ]
    }
   ],
   "source": [
    "from pymongo import MongoClient\n",
    "from emoji import UNICODE_EMOJI\n",
    "from textblob import TextBlob\n",
    "from textblob.sentiments import NaiveBayesAnalyzer\n",
    "import pandas as pd\n",
    "\n",
    "client = MongoClient('localhost', 27017)\n",
    "db = client['usa_db']\n",
    "collection = db['usa_tweets_collection']\n",
    "tweets_iterator = collection.find()\n",
    "\n",
    "pos_dict = dict()\n",
    "neg_dict = dict()\n",
    "only200 = 200\n",
    "for tweet in tweets_iterator:\n",
    "    if only200 <= 0:\n",
    "        break\n",
    "    for ch in list(tweet['text']):\n",
    "        if ch in UNICODE_EMOJI:\n",
    "            only200 -= 1\n",
    "            blob = TextBlob(tweet['text'], analyzer=NaiveBayesAnalyzer())\n",
    "            if blob.sentiment.classification == 'pos':\n",
    "                try:\n",
    "                    pos_dict[ch] += 1\n",
    "                except KeyError:\n",
    "                    pos_dict[ch] = 1\n",
    "            else:\n",
    "                try:\n",
    "                    neg_dict[ch] += 1\n",
    "                except KeyError:\n",
    "                    neg_dict[ch] = 1\n",
    "\n",
    "pos_dict = sorted(pos_dict.items(), key=lambda x: -x[1])\n",
    "neg_dict = sorted(neg_dict.items(), key=lambda x: -x[1])                    \n",
    "print('positive emojis = ', pos_dict[:5])\n",
    "print()\n",
    "print('negative_emojis = ', neg_dict[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stay tuned for more!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
