{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collecting and Analyzing Tweets\n",
    "\n",
    "To replicate my set up and run this notebook, please visit https://github.com/galletti94/Tweet-Monitor \n",
    "\n",
    "\n",
    "## Exploratory Data Analysis\n",
    "\n",
    "I love exploring data! It is such an important first step because, as you will see, it gives us intuition about what models may or may not work and why, when we try learning from the data later.\n",
    "\n",
    "### Let's get some tweets!\n",
    "\n",
    "For this step we use the twitter API which requires you to have a twitter account. Twitter gives you access keys which are unique to your account. These keys will go in a file called keys.txt which we make sure to include in the .gitignore file so that these are not made publically available. Let's get started!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracking: United States\n"
     ]
    }
   ],
   "source": [
    "import tweepy\n",
    "import json\n",
    "from pymongo import MongoClient\n",
    "from __future__ import print_function\n",
    "\n",
    "MONGO_HOST = 'mongodb://localhost/usa_db'\n",
    "\n",
    "LOCATION = [-127.3,24.1,-65.9,51.8]\n",
    "\n",
    "# get credentials from the keys.txt file\n",
    "keys_file = open(\"keys.txt\")\n",
    "lines = keys_file.readlines()\n",
    "consumer_key = lines[0].rstrip()\n",
    "consumer_secret = lines[1].rstrip()\n",
    "access_token = lines[2].rstrip()\n",
    "access_token_secret = lines[3].rstrip()\n",
    "keys_file.close()\n",
    "\n",
    "class StreamListener(tweepy.StreamListener):\n",
    "    # This is a class provided by tweepy to access the Twitter Streaming API.\n",
    "\n",
    "    def on_connect(self):\n",
    "        # Called initially to connect to the Streaming API\n",
    "        print(\"You are now connected to the streaming API.\")\n",
    "\n",
    "    def on_error(self, status_code):\n",
    "        print('An Error has occured: ' + repr(status_code))\n",
    "        return False\n",
    "\n",
    "    def on_data(self, data):\n",
    "        try:\n",
    "            client = MongoClient(MONGO_HOST)\n",
    "            db = client.usa_db\n",
    "            \n",
    "            datajson = json.loads(data) # Decode the JSON from Twitter\n",
    "\n",
    "            # grab the 'created_at' data from the Tweet to use for display\n",
    "            created_at = datajson['created_at']\n",
    "            \n",
    "            # only get tweets that have geo location enabled\n",
    "            if datajson['coordinates']:\n",
    "                # print out a message to the screen that we have collected a tweet\n",
    "                print(\"Tweet collected at \" + str(created_at))\n",
    "                db.usa_tweets_collection.insert_one(datajson) #insert into db\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "listener = StreamListener(api=tweepy.API(wait_on_rate_limit=True))\n",
    "streamer = tweepy.Stream(auth=auth, listener=listener)\n",
    "\n",
    "print(\"Tracking: \" + 'United States')\n",
    "#streamer.filter(locations=LOCATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome - now we can let this run and collect some tweets!\n",
    "\n",
    "After waiting a few minutes for your database to fill up, you can hit CTRL + C to stop the collection and stop the program.\n",
    "\n",
    "### What do we have here?\n",
    "\n",
    "Let's take a look at the tweets we collected!\n",
    "\n",
    "### Where are in the US are these tweets coming from?\n",
    "\n",
    "We can use folium to map the coordinates of the tweets on a map:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "import folium\n",
    "\n",
    "client = MongoClient('localhost', 27017)\n",
    "db = client['usa_db']\n",
    "collection = db['usa_tweets_collection']\n",
    "tweets_iterator = collection.find()\n",
    "\n",
    "mymap = folium.Map(location=[45.372, -121.6972], zoom_start=4)\n",
    "\n",
    "for tweet in tweets_iterator:\n",
    "    folium.CircleMarker(location=list(reversed(tweet['coordinates']['coordinates']))).add_to(mymap)\n",
    "    \n",
    "mymap.save('map.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the above and opening map.html in a browser gives the following:\n",
    "\n",
    "![Image](./tweetsUSA.jpg)\n",
    "\n",
    "Nice. Let's look at what kinds of emojis people use!\n",
    "\n",
    "### Emojis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('‚ù§', 164), ('üî•', 160), ('üéÑ', 121), ('üòç', 118), ('üèæ', 112), ('üèº', 112), ('üòÇ', 104), ('üèª', 90), ('üèΩ', 81), ('‚ú®', 79), ('üôå', 68), ('üí™', 67), ('üíØ', 62), ('üôè', 60), ('‚ùÑ', 60)]\n"
     ]
    }
   ],
   "source": [
    "from emoji import UNICODE_EMOJI\n",
    "\n",
    "client = MongoClient('localhost', 27017)\n",
    "db = client['usa_db']\n",
    "collection = db['usa_tweets_collection']\n",
    "tweets_iterator = collection.find()\n",
    "\n",
    "d = dict()\n",
    "i = 0\n",
    "for tweet in tweets_iterator:\n",
    "  for ch in list(tweet['text']):  #remember emojis are characters not words\n",
    "    if ch in UNICODE_EMOJI:\n",
    "      try:\n",
    "        d[ch] += 1\n",
    "      except KeyError:\n",
    "        d[ch] = 1\n",
    "\n",
    "d = sorted(d.items(), key=lambda x: -x[1])\n",
    "print(d[:15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When this was written it was close to christmas so I guess the second and third emojis make sense.\n",
    "\n",
    "\n",
    "### Sentiment Analysis\n",
    "\n",
    "\n",
    "We can analyze the words of the tweets to get a sense of whether the tweet has positive sentiment or negative sentiment. We can aggregate these and get a sense of the general mood of the US at this time of year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('pos', 74), ('neg', 26)]\n",
      "\n",
      "Number of Tweets =  100\n",
      "\n",
      "Number of tweets with location enabled =  95\n"
     ]
    }
   ],
   "source": [
    "from pymongo import MongoClient\n",
    "from textblob import TextBlob\n",
    "from textblob.sentiments import NaiveBayesAnalyzer\n",
    "\n",
    "client = MongoClient('localhost', 27017)\n",
    "db = client['usa_db']\n",
    "collection = db['usa_tweets_collection']\n",
    "tweets_iterator = collection.find()\n",
    "\n",
    "tweetCnt = 0\n",
    "locEnabled = 0\n",
    "d = dict()\n",
    "only100 = 100\n",
    "for tweet in tweets_iterator:\n",
    "    if only100 <= 0:\n",
    "        break\n",
    "    only100 -= 1\n",
    "    tweetCnt += 1\n",
    "    if tweet['user']['location']:\n",
    "      locEnabled += 1\n",
    "    \n",
    "    blob = TextBlob(tweet['text'], analyzer=NaiveBayesAnalyzer())\n",
    "    try:\n",
    "        d[blob.sentiment.classification] += 1\n",
    "    except KeyError:\n",
    "        d[blob.sentiment.classification] = 1\n",
    "\n",
    "d = sorted(d.items(), key=lambda x: -x[1])\n",
    "print(d)\n",
    "print()\n",
    "print('Number of Tweets = ', tweetCnt)\n",
    "print()\n",
    "print('Number of tweets with location enabled = ', locEnabled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like a majority of tweets have positive sentiment but this analysis was only conducted on a subset of the data collected since sentiment analysis is expensive to compute.\n",
    "\n",
    "Maybe next we can see which emojis are correlated with which sentiment!\n",
    "\n",
    "### Emoji vs Sentiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive emojis =  [('üåπ', 9), ('‚ù§', 9), ('‚ú®', 8), ('üéÑ', 6), ('üé∂', 6)]\n",
      "\n",
      "negative_emojis =  [('üò≠', 7), ('üî•', 6), ('üí¶', 4), ('‚ù£', 2), ('‚õì', 2)]\n"
     ]
    }
   ],
   "source": [
    "from pymongo import MongoClient\n",
    "from emoji import UNICODE_EMOJI\n",
    "from textblob import TextBlob\n",
    "from textblob.sentiments import NaiveBayesAnalyzer\n",
    "\n",
    "client = MongoClient('localhost', 27017)\n",
    "db = client['usa_db']\n",
    "collection = db['usa_tweets_collection']\n",
    "tweets_iterator = collection.find()\n",
    "\n",
    "pos_dict = dict()\n",
    "neg_dict = dict()\n",
    "only200 = 200\n",
    "for tweet in tweets_iterator:\n",
    "    if only200 <= 0:\n",
    "        break\n",
    "    for ch in list(tweet['text']):\n",
    "        if ch in UNICODE_EMOJI:\n",
    "            only200 -= 1\n",
    "            blob = TextBlob(tweet['text'], analyzer=NaiveBayesAnalyzer())\n",
    "            if blob.sentiment.classification == 'pos':\n",
    "                try:\n",
    "                    pos_dict[ch] += 1\n",
    "                except KeyError:\n",
    "                    pos_dict[ch] = 1\n",
    "            else:\n",
    "                try:\n",
    "                    neg_dict[ch] += 1\n",
    "                except KeyError:\n",
    "                    neg_dict[ch] = 1\n",
    "\n",
    "pos_dict = sorted(pos_dict.items(), key=lambda x: -x[1])\n",
    "neg_dict = sorted(neg_dict.items(), key=lambda x: -x[1])                    \n",
    "print('positive emojis = ', pos_dict[:5])\n",
    "print()\n",
    "print('negative_emojis = ', neg_dict[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! It seems intuitive that a rose, a heart, and stars be associated with positive sentiment and a crying face would be associated with negative sentiment. It is good to see these results support our intuition!\n",
    "\n",
    "Now we would like to know what kinds of tweets do people with location disabled make?\n",
    "\n",
    "### Location Disabled Tweets - Emojis\n",
    "\n",
    "First let's look at the kinds of emojis are used in both groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Tweets =  23226\n",
      "\n",
      "location enabled emojis =  [('‚ù§', 169), ('üî•', 164), ('üéÑ', 124), ('üòç', 122), ('üèº', 115), ('üèæ', 114), ('üòÇ', 104), ('üèª', 95), ('üèΩ', 93), ('‚ú®', 81)]\n",
      "\n",
      "location disabled emojis =  [('üòÇ', 125), ('üò≠', 81), ('‚ôÄ', 28), ('üèæ', 28), ('üèΩ', 28), ('üòç', 27), ('\\U0001f926', 26), ('‚ù§', 26), ('üî•', 25), ('‚ùÑ', 25)]\n"
     ]
    }
   ],
   "source": [
    "from pymongo import MongoClient\n",
    "from emoji import UNICODE_EMOJI\n",
    "\n",
    "client = MongoClient('localhost', 27017)\n",
    "db = client['usa_db']\n",
    "collection = db['usa_tweets_collection']\n",
    "tweets_iterator = collection.find()\n",
    "\n",
    "enabled_dict = dict()\n",
    "disabled_dict = dict()\n",
    "tweetcnt = 0\n",
    "for tweet in tweets_iterator:\n",
    "    tweetcnt += 1\n",
    "    for ch in list(tweet['text']):\n",
    "        if ch in UNICODE_EMOJI:\n",
    "            if tweet['coordinates']:\n",
    "                try:\n",
    "                    enabled_dict[ch] += 1\n",
    "                except KeyError:\n",
    "                    enabled_dict[ch] = 1\n",
    "            else:\n",
    "                try:\n",
    "                    disabled_dict[ch] += 1\n",
    "                except KeyError:\n",
    "                    disabled_dict[ch] = 1\n",
    "\n",
    "enabled_dict = sorted(enabled_dict.items(), key=lambda x: -x[1])\n",
    "disabled_dict = sorted(disabled_dict.items(), key=lambda x: -x[1])\n",
    "print('Number of Tweets = ', tweetcnt)\n",
    "print()\n",
    "print('location enabled emojis = ', enabled_dict[:10])\n",
    "print()\n",
    "print('location disabled emojis = ', disabled_dict[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like people with location disabled use in majority emojis that we evaluated earlier to be negative sentiment! Now that's very interesting!\n",
    "\n",
    "I wonder if there is a difference in what topics these two groups post about. Let's look at the tags in their tweets to get a sense of what these people post about!\n",
    "\n",
    "### Location Disabled Tweets - Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Tweets =  23226\n",
      "\n",
      "location enabled tags =  [('#job', 7322), ('#CareerArc', 6157), ('#Hiring', 5750), ('#hiring', 2842), ('#Jobs', 1996), ('#Job', 1995), ('#Retail', 1040), ('#Hospitality', 750), ('#Sales', 460), ('#Nursing', 433)]\n",
      "\n",
      "location disabled tags =  [('#snow', 2), ('#ImpeachTrump', 2), ('#TheResistance', 2), ('#netneutrality', 2), ('#PokemonGO', 2), ('#dahlia', 1), ('#SugarLandTX', 1), ('#loser', 1), ('#BetterTogether', 1), ('#GoHawks', 1)]\n"
     ]
    }
   ],
   "source": [
    "from pymongo import MongoClient\n",
    "import re\n",
    "\n",
    "client = MongoClient('localhost', 27017)\n",
    "db = client['usa_db']\n",
    "collection = db['usa_tweets_collection']\n",
    "tweets_iterator = collection.find()\n",
    "\n",
    "enabled_dict = dict()\n",
    "disabled_dict = dict()\n",
    "tweetcnt = 0\n",
    "for tweet in tweets_iterator:\n",
    "    tweetcnt += 1\n",
    "    for tag in re.findall(r'\\B(\\#[a-zA-Z]+\\b)(?!;)', tweet['text']):\n",
    "        if tweet['coordinates']:\n",
    "            try:\n",
    "                enabled_dict[tag] += 1\n",
    "            except KeyError:\n",
    "                enabled_dict[tag] = 1\n",
    "        else:\n",
    "            try:\n",
    "                disabled_dict[tag] += 1\n",
    "            except KeyError:\n",
    "                disabled_dict[tag] = 1\n",
    "\n",
    "enabled_dict = sorted(enabled_dict.items(), key=lambda x: -x[1])\n",
    "disabled_dict = sorted(disabled_dict.items(), key=lambda x: -x[1])\n",
    "print('Number of Tweets = ', tweetcnt)\n",
    "print()\n",
    "print('location enabled tags = ', enabled_dict[:10])\n",
    "print()\n",
    "print('location disabled tags = ', disabled_dict[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like tweets with location disabled don't tag very much. I will let you make your own conclusions about the content type...\n",
    "\n",
    "Let's start from a specific set of keywords and observe the distribution of location enabled vs disabled!\n",
    "\n",
    "### Keywords about Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracking: ['#deeplearning', '#computervision', '#datascience', '#bigdata']\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import tweepy\n",
    "import json\n",
    "from pymongo import MongoClient\n",
    "\n",
    "MONGO_HOST = 'mongodb://localhost/twitterdb'\n",
    "\n",
    "WORDS = ['#deeplearning', '#computervision', '#datascience', '#bigdata']\n",
    "\n",
    "keys_file = open(\"keys.txt\")\n",
    "lines = keys_file.readlines()\n",
    "consumer_key = lines[0].rstrip()\n",
    "consumer_secret = lines[1].rstrip()\n",
    "access_token = lines[2].rstrip()\n",
    "access_token_secret = lines[3].rstrip()\n",
    "\n",
    "class StreamListener(tweepy.StreamListener):\n",
    "    def on_connect(self):\n",
    "        print(\"You are now connected to the streaming API.\")\n",
    "\n",
    "    def on_error(self, status_code):\n",
    "        print('An Error has occured: ' + repr(status_code))\n",
    "        return False\n",
    "\n",
    "    def on_data(self, data):\n",
    "        # This is the meat of the script...it connects to your mongoDB and stores the tweet\n",
    "        try:\n",
    "            client = MongoClient(MONGO_HOST)\n",
    "            db = client.twitterdb\n",
    "            datajson = json.loads(data)\n",
    "            created_at = datajson['created_at']\n",
    "            print(\"Tweet collected at \" + str(created_at))\n",
    "            db.twitter_search.insert(datajson)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "listener = StreamListener(api=tweepy.API(wait_on_rate_limit=True))\n",
    "streamer = tweepy.Stream(auth=auth, listener=listener)\n",
    "\n",
    "print(\"Tracking: \" + str(WORDS))\n",
    "streamer.filter(track=WORDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, keep this runnning for a bit while to collect some tweets. Now we can do some more analysis:\n",
    "\n",
    "### Location of ML people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Tweets =  1019\n",
      "location enabled =  0\n",
      "location disabled =  1019\n",
      "emojis =  [('üó£', 20), ('üëè', 8), ('üëâ', 6), ('üëÄ', 1), ('‚Ñ¢', 1), ('üì¶', 1), ('üì¢', 1), ('üê∏', 1), ('üì£', 1), ('‚ñ∂', 1), ('üèΩ', 1), ('¬Æ', 1), ('üìà', 1), ('üö®', 1), ('üåê', 1)]\n"
     ]
    }
   ],
   "source": [
    "from pymongo import MongoClient\n",
    "from emoji import UNICODE_EMOJI\n",
    "\n",
    "client = MongoClient('localhost', 27017)\n",
    "db = client['twitterdb']\n",
    "collection = db['twitter_search']\n",
    "tweets_iterator = collection.find()\n",
    "\n",
    "d = dict()\n",
    "enabled = 0\n",
    "disabled = 0\n",
    "tweetcnt = 0\n",
    "for tweet in tweets_iterator:\n",
    "    tweetcnt += 1\n",
    "    \n",
    "    for ch in list(tweet['text']):  #remember emojis are characters not words\n",
    "        if ch in UNICODE_EMOJI:\n",
    "          try:\n",
    "            d[ch] += 1\n",
    "          except KeyError:\n",
    "            d[ch] = 1\n",
    "    \n",
    "    if tweet['coordinates']:\n",
    "        enabled += 1\n",
    "    else:\n",
    "        disabled += 1\n",
    "\n",
    "d = sorted(d.items(), key=lambda x: -x[1])\n",
    "print('Total Tweets = ', tweetcnt)\n",
    "print('location enabled = ', enabled)\n",
    "print('location disabled = ', disabled)\n",
    "print('emojis = ', d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like people who post about these keywords don't share their location! Interesting emojis as well!\n",
    "\n",
    "Going back to USA tweets, we can analyze the source of the tweet to understand what people post about on which device for example. First we will look at the distribution of devices, then we can plot these and finally look at what emojis and tags are used with each.\n",
    "\n",
    "### Source of Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('TweetMyJOBS', 9585), ('Instagram', 6765), ('Twitter for iPhone', 1387), ('Foursquare', 881), ('SafeTweet by TweetMyJOBS', 665), ('NYRegions', 392), ('Cities', 360), ('Twitter for Android', 324), ('TownTweet', 300), ('Untappd', 140)]\n"
     ]
    }
   ],
   "source": [
    "from pymongo import MongoClient\n",
    "\n",
    "client = MongoClient('localhost', 27017)\n",
    "db = client['usa_db']\n",
    "collection = db['usa_tweets_collection']\n",
    "tweets_iterator = collection.find()\n",
    "\n",
    "d = dict()\n",
    "for tweet in tweets_iterator:\n",
    "    s = ''.join(tweet['source'].split('>')[1].split('<')[0])\n",
    "    if s:\n",
    "        try:\n",
    "            d[s] += 1\n",
    "        except KeyError:\n",
    "            d[s] = 1\n",
    "\n",
    "d = sorted(d.items(), key=lambda x: -x[1])\n",
    "print(d[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's map some of these!\n",
    "\n",
    "### Map of devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "import folium\n",
    "\n",
    "client = MongoClient('localhost', 27017)\n",
    "db = client['usa_db']\n",
    "collection = db['usa_tweets_collection']\n",
    "tweets_iterator = collection.find()\n",
    "\n",
    "mymap = folium.Map(location=[45.372, -121.6972], zoom_start=4)\n",
    "\n",
    "for tweet in tweets_iterator:\n",
    "    if ''.join(tweet['source'].split('>')[1].split('<')[0]) == 'TweetMyJOBS' and tweet['coordinates']:\n",
    "        folium.CircleMarker(location=list(reversed(tweet['coordinates']['coordinates']))).add_to(mymap)\n",
    "    \n",
    "mymap.save('map3.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Image](./tweetsUSA2.jpg)\n",
    "\n",
    "It is interesting to note that many people who use this feature have their location enabled. If we now plot the tweets made on the Twitter App for iPhone, the results are drastically different. Are your location settings application dependent? That is, if you share an instagram post on twitter, is your location setting that of instagram or that of twitter? Someone should test this out!\n",
    "\n",
    "![Image](./tweetsUSA3.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stay tuned for more!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
